{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjIR6XirGcOwHl6AblqUEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaejuna/SparkML/blob/main/%08Spark_ch5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bRVYyG731V6",
        "outputId": "28d90c00-88e9-4b17-f4c6-f3f1a6891d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=f712da82b7cc505c551113961abc0c71c5873fc3a14d97ba8673e53ee052d5a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.4.0\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.17, OpenJDK 64-Bit Server VM, 11.0.18\n",
            "Branch HEAD\n",
            "Compiled by user xinrong.meng on 2023-04-07T02:18:01Z\n",
            "Revision 87a5442f7ed96b11051d8a9333476d080054e5a0\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCjhK2Xvck0m",
        "outputId": "adf8b507-59cf-4837-d851-c9c52fc6b86d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 스파크 SQL UDF"
      ],
      "metadata": {
        "id": "JrNEWA3YFXu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xGGP969526SY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"ch05\").getOrCreate()\n",
        "\n",
        "# 스파크 SQL UDF 파이썬 예제\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# 큐브 함수 생성\n",
        "def cubed(s):\n",
        "  return s * s * s\n",
        "\n",
        "data = [(1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,)]\n",
        "df = spark.createDataFrame(data, schema=['id'])\n",
        "\n",
        "# UDF로 등록\n",
        "spark.udf.register(\"cubed\", cubed, LongType())\n",
        "\n",
        "# 임시 뷰 생성\n",
        "df.createOrReplaceTempView('udf_test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 큐브 UDF를 사용하여 쿼리\n",
        "spark.sql(\"SELECT id, cubed(id) AS id_cubed FROM udf_test\").show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1oLxgwd3wt2",
        "outputId": "58661d8e-3956-43dc-d514-ee26366d19a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|id_cubed|\n",
            "+---+--------+\n",
            "|  1|       1|\n",
            "|  2|       8|\n",
            "|  3|      27|\n",
            "|  4|      64|\n",
            "|  5|     125|\n",
            "|  6|     216|\n",
            "|  7|     343|\n",
            "|  8|     512|\n",
            "|  9|     729|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 판다스 UDF"
      ],
      "metadata": {
        "id": "doW6gXBaFcSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 판다스 가져오기\n",
        "import pandas as pd\n",
        "\n",
        "# 파이스파크 SQL 함수와 pandas_udf 가져오기\n",
        "from pyspark.sql.functions import col, pandas_udf\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# 큐브 함수 선언 (파이스파크 UDF랑 다른 점 확인)\n",
        "def cubed(a: pd.Series) -> pd.Series:\n",
        "  return a * a * a\n",
        "\n",
        "# 큐브 함수에 대한 판다스 UDF 생성\n",
        "cubed_udf = pandas_udf(cubed, returnType=LongType())"
      ],
      "metadata": {
        "id": "su31P9JE38yE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판다스 시리즈 생성\n",
        "x = pd.Series([1,2,3])\n",
        "\n",
        "# 로컬 판다스 데이터를 실행하는 pandas_udf에 대한 함수\n",
        "print(cubed(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uuIvB-xGP0v",
        "outputId": "d8803f51-9251-4603-af6d-65d727930f38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     1\n",
            "1     8\n",
            "2    27\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스파크 데이터 프레임 생성\n",
        "df = spark.range(1, 4)\n",
        "\n",
        "# 벡터화된 스파크 UDF(판다스 UDF)를 함수로 생성\n",
        "df.select(\"id\", cubed_udf(col('id'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFQM84NiGxm2",
        "outputId": "c5d2ecb2-5d02-475c-ba3d-eb60103c7b03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|cubed(id)|\n",
            "+---+---------+\n",
            "|  1|        1|\n",
            "|  2|        8|\n",
            "|  3|       27|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 스파크 SQL 셸 사용하기"
      ],
      "metadata": {
        "id": "49fGSmoCYlMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in $SPARK_HOME directory\n",
        "# ./bin/spark-sql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MO8-3YxDOgM",
        "outputId": "652cd445-36ba-4b80-c712-0f0d59b8128f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./bin/spark-sql: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스파크 SQL 테이블 생성\n",
        "CREATE TABLE people (name STRING, age INT);\n",
        "\n",
        "# 테이블에 데이터 삽입\n",
        "INSERT INTO people SELECET name, age FROM\n",
        "# values 문 사용\n",
        "INSERT INTO people SELECET name, age VALUES (\"Michael\", NULL);\n",
        "INSERT INTO people SELECET name, age VALUES (\"Andy\", 30);\n",
        "INSERT INTO people SELECET name, age VALUES (\"Samantha\", 19);\n",
        "\n",
        "# 스파크 SQL 쿼리 실행하기\n",
        "SHOW TABLES;\n",
        "SELECT * FROM people WHERE age < 20;\n",
        "SELECT name FROM people WHERE age IS NULL;"
      ],
      "metadata": {
        "id": "orFfqMRxYpc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 비라인 작업"
      ],
      "metadata": {
        "id": "OLcTjr2fYtL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in $SPARK_HOME directory\n",
        "# ./sbin/start-thriftserver.sh"
      ],
      "metadata": {
        "id": "p-eH9BcvYz1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 쓰리프트 서버 테스트\n",
        "./bin/beeline\n",
        "# 비라인을 구성하여 로컬 쓰리프트 서버에 연결\n",
        "!connect jdbc:hive2//localhost:10000"
      ],
      "metadata": {
        "id": "C_08EIFcY6F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#비라인으로 스파크 sql 쿼리 실행\n",
        "SHOW tables;\n",
        "SELECT * FROM people;"
      ],
      "metadata": {
        "id": "Urlrm7ZJY8G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 서버 중지하기\n",
        "./sbin/stop-thriftserver.sh"
      ],
      "metadata": {
        "id": "de5tmANzY94Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PostgreSQL"
      ],
      "metadata": {
        "id": "6vG7fKtkOFUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 읽기 방법 1 : 로드 함수를 사용하여 JDBC 소스로부터 데이터를 로드\n",
        "jdbcDF1 = (spark\n",
        "           .read\n",
        "           .format(\"jdbc\")\n",
        "           .option(\"url\", \"jdbc:postgresql://[DBSERVER]\")\n",
        "           .option(\"dbtable\", \"[SCHEMA].[TABLENAME]\")\n",
        "           .option('user', \"[USERNAME]\")\n",
        "           .option('password', \"[PASSWORD]\")\n",
        "           .load())\n",
        "\n",
        "# 읽기 방법 2 : jdbc 함수를 사용하여 JDBC 소스로부터 데이터를 로드\n",
        "jdbcDF2 = (spark\n",
        "           .read\n",
        "           .jdbc(\"jdbc:postgresql://[DBSERVER]\", \"[SCHEMA].[TABLENAME]\",\n",
        "                 properties={'user':\"[USERNAME]\", 'password':\"[PASSWORD]\"}))\n",
        "\n",
        "# 쓰기 방법 1 : 저장 함수를 사용하여 JDBC 소스에 데이터를 저장\n",
        "(jdbcDF1\n",
        " .write\n",
        " .format(\"jdbc\")\n",
        " .option(\"url\", \"jdbc:postgresql://[DBSERVER]\")\n",
        " .option(\"dbtable\", \"[SCHEMA].[TABLENAME]\")\n",
        " .option('user', \"[USERNAME]\")\n",
        " .option('password', \"[PASSWORD]\")\n",
        " .save())\n",
        "\n",
        "# 쓰기 방법 2 : jdbc 함수를 사용하여 JDBC 소스에 데이터르 저장\n",
        "(jdbcDF2\n",
        " .write\n",
        " .jdbc(\"jdbc:postgresql://[DBSERVER]\", \"[SCHEMA].[TABLENAME]\",\n",
        "       properties={'user':\"[USERNAME]\", 'password':\"[PASSWORD]\"}))"
      ],
      "metadata": {
        "id": "-4c9of5SEgqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MySQL"
      ],
      "metadata": {
        "id": "itneqF1bS_Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로드 함수를 사용하여 JDBC 소스로부터 데이터를 로드\n",
        "jdbcDF = (spark\n",
        "          .read\n",
        "          .format(\"jdbc\")\n",
        "          .option(\"url\", \"jdbc:mysql://[DBSERVER]:3306/[DATABASE]\")\n",
        "          .option(\"driver\", \"com.myslql.jdbcDriver\")\n",
        "          .option(\"dbtable\", \"[TABLENAME]\")\n",
        "          .option('user', \"[USERNAME]\")\n",
        "          .option('password', \"[PASSWORD]\")\n",
        "          .load())\n",
        "\n",
        "# 저장 함수를 사용하여 JDBC 소스에 데이터를 저장\n",
        "(jdbcDF\n",
        " .write\n",
        " .format(\"jdbc\")\n",
        " .option(\"url\", \"jdbc:mysql://[DBSERVER]:3306/[DATABASE]\")\n",
        " .option(\"driver\", \"com.myslql.jdbcDriver\")\n",
        " .option(\"dbtable\", \"[TABLENAME]\")\n",
        " .option('user', \"[USERNAME]\")\n",
        " .option('password', \"[PASSWORD]\")\n",
        " .save())"
      ],
      "metadata": {
        "id": "87XhO0lxS_CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 에저 코스모스 DB"
      ],
      "metadata": {
        "id": "MebNg7zKUHlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 애저 코스모스 DB로부터 데이터 로드\n",
        "## 설정 읽기\n",
        "query = \"SELECT c.colA, c.coln FROM c WHERE c.origin = 'SEA'\"\n",
        "readConfig = {\n",
        "    \"Endpoint\" : \"https://[ACCOUNT].documents.azure.com:443\",\n",
        "    \"MasterKey\" : \"[MASTER KEY]\",\n",
        "    \"Database\" : \"[DATABASE]\",\n",
        "    \"preferredRegions\" : \"Central US; East US2\",\n",
        "    \"Collection\" : \"[COLLECTION]\",\n",
        "    \"SamplingRatio\" : \"1.0\"\n",
        "    \"schema_samplesize\" : \"1000\",\n",
        "    \"query_pagesize\" : \"2147483647\",\n",
        "    \"query_custom\" : query\n",
        "}\n",
        "\n",
        "# azure-cosmosdb-spark를 통해 연결하여 스파크 데이터 프레임 생성\n",
        "df = (spark\n",
        "      .read\n",
        "      .format(\"com.microsoft.azure.cosmosdb.spark\")\n",
        "      .option(**readConfig)\n",
        "      .load())\n",
        "\n",
        "# 비행 수 카운트\n",
        "df.count()\n",
        "\n",
        "# 애저 코스모스 DB에 데이터 저장\n",
        "# 설정 쓰기\n",
        "writeConfig = {\n",
        "    \"Endpoint\" : \"https://[ACCOUNT].documents.azure.com:443\",\n",
        "    \"MasterKey\" : \"[MASTER KEY]\",\n",
        "    \"Database\" : \"[DATABASE]\",\n",
        "    \"Collection\" : \"[COLLECTION]\",\n",
        "    \"Upsert\" : \"true\"\n",
        "}\n",
        "\n",
        "# 애저 코스모스 DB에 데이터 프레임 업서트 하기\n",
        "(df.write\n",
        " .format(\"com.microsoft.azure.cosmosdb.spark\")\n",
        " .options(**writeConfig)\n",
        " .save())"
      ],
      "metadata": {
        "id": "dAVj2MEWUMXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 고차 함수"
      ],
      "metadata": {
        "id": "CyJD-6cL_gNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DF 생성\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([StructField(\"celsius\", ArrayType(IntegerType()))])\n",
        "\n",
        "t_list = [[35, 36, 32, 30, 40, 42, 38]], [[31, 32, 34, 55, 56]]\n",
        "t_c = spark.createDataFrame(t_list, schema)\n",
        "t_c.createOrReplaceTempView(\"tC\")\n",
        "\n",
        "# DF 출력\n",
        "t_c.show()"
      ],
      "metadata": {
        "id": "DFmQptatVTIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f04822-45c3-4338-a6bd-4b77c6b05692"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             celsius|\n",
            "+--------------------+\n",
            "|[35, 36, 32, 30, ...|\n",
            "|[31, 32, 34, 55, 56]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 고차 함수 쿼리 (transform)\n",
        "spark.sql(\"\"\"\n",
        "SELECT celsius, \n",
        "transform(celsius, t -> ((t * 9) div 5) + 32)) AS fahrenheit\n",
        "FROM tC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "gPuc1RfHAQTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 고차 함수 쿼리 (filter)\n",
        "spark.sql(\"\"\"\n",
        "SELECT celsius, \n",
        "filter(celsius, t -> t > 38) AS high\n",
        "FROM tC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "Y8pPzPJZDMew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 고차 함수 쿼리 (exists)\n",
        "spark.sql(\"\"\"\n",
        "SELECT celsius, \n",
        "  exists(celsius, t -> t = 38) as threshold\n",
        "FROM tC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "tZeT8C8dEzcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 고차 함수 쿼리 (reduce)\n",
        "spark.sql(\"\"\"\n",
        "SELECT celsius, \n",
        "  reduce(\n",
        "    celsius,\n",
        "    0,\n",
        "    (t, acc) -> t + acc,\n",
        "    acc -> (acc div size(celsius) * 9 div 5) + 32\n",
        "  ) as avgFahrenheit\n",
        "FROM tC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "R-a-xvr2G3dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 일반적인 데이터 프레임 및 스파크 SQL 작업"
      ],
      "metadata": {
        "id": "J8OEhuzNMvRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 경로 설정\n",
        "from pyspark.sql.functions import expr\n",
        "tripdelaysFilePath = \"/content/drive/MyDrive/BOAZ/엔지/Spark Study/databricks-datasets/learning-spark-v2/flights/departuredelays.csv\"\n",
        "airportsnaFilePath = \"/content/drive/MyDrive/BOAZ/엔지/Spark Study/databricks-datasets/learning-spark-v2/flights/airport-codes-na.txt\"\n",
        "\n",
        "# 공항 데이터세트 읽어 오기\n",
        "airportsna = (spark.read\n",
        "              .format(\"csv\")\n",
        "              .options(header=\"true\", inferSchema=\"true\", sep=\"\\t\")\n",
        "              .load(airportsnaFilePath))\n",
        "\n",
        "airportsna.createOrReplaceTempView(\"airports_na\")\n",
        "\n",
        "# 출발 지연 데이터세트를 읽어 오기\n",
        "departureDelays = (spark.read\n",
        "                   .format(\"csv\")\n",
        "                   .options(header=\"true\")\n",
        "                   .load(tripdelaysFilePath))\n",
        "\n",
        "departureDelays = (departureDelays\n",
        "                   .withColumn(\"delay\", expr(\"CAST(delay as INT) as delay\"))\n",
        "                   .withColumn(\"distance\", expr(\"CAST(distance as INT) as distance\")))\n",
        "\n",
        "departureDelays.createOrReplaceTempView(\"departureDelays\")\n",
        "\n",
        "# 임시 작은 테이블(뷰) 생성\n",
        "foo = (departureDelays\n",
        "       .filter(expr(\"\"\"origin == 'SEA' AND destination == 'SFO' and date like '01010%' and delay > 0\"\"\")))\n",
        "foo.createOrReplaceTempView(\"foo\")\n"
      ],
      "metadata": {
        "id": "LW43en4SNAuI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query 넣기\n",
        "spark.sql(\"SELECT * FROM airports_na LIMIT 10\").show()\n",
        "spark.sql(\"SELECT * FROM departureDelays LIMIT 10\").show()\n",
        "spark.sql(\"SELECT * FROm foo\").show()"
      ],
      "metadata": {
        "id": "32kWHFqyPG47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e18ae9b-6b19-47b3-8ad0-b72d1d52daeb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-------+----+\n",
            "|       City|State|Country|IATA|\n",
            "+-----------+-----+-------+----+\n",
            "| Abbotsford|   BC| Canada| YXX|\n",
            "|   Aberdeen|   SD|    USA| ABR|\n",
            "|    Abilene|   TX|    USA| ABI|\n",
            "|      Akron|   OH|    USA| CAK|\n",
            "|    Alamosa|   CO|    USA| ALS|\n",
            "|     Albany|   GA|    USA| ABY|\n",
            "|     Albany|   NY|    USA| ALB|\n",
            "|Albuquerque|   NM|    USA| ABQ|\n",
            "| Alexandria|   LA|    USA| AEX|\n",
            "|  Allentown|   PA|    USA| ABE|\n",
            "+-----------+-----+-------+----+\n",
            "\n",
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01011245|    6|     602|   ABE|        ATL|\n",
            "|01020600|   -8|     369|   ABE|        DTW|\n",
            "|01021245|   -2|     602|   ABE|        ATL|\n",
            "|01020605|   -4|     602|   ABE|        ATL|\n",
            "|01031245|   -4|     602|   ABE|        ATL|\n",
            "|01030605|    0|     602|   ABE|        ATL|\n",
            "|01041243|   10|     602|   ABE|        ATL|\n",
            "|01040605|   28|     602|   ABE|        ATL|\n",
            "|01051245|   88|     602|   ABE|        ATL|\n",
            "|01050605|    9|     602|   ABE|        ATL|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n",
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Union"
      ],
      "metadata": {
        "id": "4eNy7t3EPgRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 테이블 결합\n",
        "bar = departureDelays.union(foo)\n",
        "bar.createOrReplaceTempView(\"bar\")\n",
        "\n",
        "# 결합된 결과 보기(특정 시간 범위에 대한 SEA와 SFO를 필터)\n",
        "bar.filter(expr(\"\"\"origin == 'SEA' AND destination == 'SFO' AND date LIKE '01010%' AND delay > 0\"\"\")).show()"
      ],
      "metadata": {
        "id": "dGcyI0tuPiSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bb827b-fdc6-46b7-bd33-235f4e61dbc3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bar DF는 foo와 delays의 결합입으로 중복됨을 확인할 수 있다.\n",
        "spark.sql(\"\"\"\n",
        "  SELECT *\n",
        "  FROM bar\n",
        "  WHERE origin = 'SEA'\n",
        "    AND destination = 'SFO'\n",
        "    AND date LIKE '01010%'\n",
        "    AND delay > 0\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "yZA2sZtsQhRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Join"
      ],
      "metadata": {
        "id": "CMTtM9C6RCud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 출발 지연 데이터(foo)와 공항 정보의 inner 조인\n",
        "foo.join(\n",
        "    airports,\n",
        "    airports.IATA == foo.origin\n",
        ").select(\"City\", \"State\", \"date\", \"delay\", \"distance\", \"destination\").show()"
      ],
      "metadata": {
        "id": "hrXNDVwmRD-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL 예제\n",
        "spark.sql(\"\"\"\n",
        "SELECT a.City, a.State, f.date, f.delay, f.distance, f.destination\n",
        "  FROM foo f\n",
        "  JOIN airports_na a\n",
        "    ON a.IATA = f.origin\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "s_i8tS2PSNwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 윈도우"
      ],
      "metadata": {
        "id": "4RwxUVfhSlDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEA, SFO, JFK에서 출발하여 특정 목적지 위치로 이동하는 항공편 검토\n",
        "DROP TABLE IF EXISTS departureDelaysWindow;\n",
        "\n",
        "CREATE TABLE departureDelaysWindow AS\n",
        "SELECT origin, destination, SUM(delay) AS TotalDelays\n",
        "FROM departureDelays\n",
        "WHERE origin IN ('SEA', 'SFO', 'JFK')\n",
        "AND destination IN ('SEA', 'SFO', 'JFK', 'DEN', 'ORD', 'LAX', 'ATL')\n",
        "GROUP BY origin, distination;\n",
        "\n",
        "SELECT * FROM departureDelaysWindow"
      ],
      "metadata": {
        "id": "HDyfHkmiSnBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 출방 공항에 대해 가장 많은 지연이 발생한 3개의 목적지 찾기\n",
        "SELECT origin, destination, SUM(TotalDelays) AS TotalDelays\n",
        "FROM departureDelaysWindow\n",
        "WHERE origin = '[ORIGIN]'\n",
        "GROUP BY origin, destination\n",
        "ORDER BY SUM(TotalDelays) DESC\n",
        "LIMIT 3"
      ],
      "metadata": {
        "id": "Svml5lnPUV3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# density_rank() 사용하여 위 쿼리 보완\n",
        "spark.sql(\"\"\"\n",
        "SELECT origin, destination, TotalDelays, rank\n",
        "FROM (\n",
        "  SELECT origin, destination, TotalDelays,\n",
        "  dense_rank() OVER (PARTITION BY origin ORDER BY TotalDelays DESC) AS rank\n",
        "  FROM departureDelaysWindow\n",
        ") t\n",
        "WHERE rank <= 3\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "zx-UMYlgUxxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 수정"
      ],
      "metadata": {
        "id": "l-2biY9JVtxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 열 추가 \n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "foo.show()\n",
        "\n",
        "foo2 = (foo.withColumn(\n",
        "    \"status\",\n",
        "    expr(\"CASE WHEN delay <= 10 THEN 'On-time' ELSE 'Delayed' END\" )\n",
        "))\n",
        "\n",
        "foo2.show()"
      ],
      "metadata": {
        "id": "qisVQvwgVusV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c324dbe8-b581-4291-a16e-8ead5297fb4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "|    date|delay|distance|origin|destination| status|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "|01010710|   31|     590|   SEA|        SFO|Delayed|\n",
            "|01010955|  104|     590|   SEA|        SFO|Delayed|\n",
            "|01010730|    5|     590|   SEA|        SFO|On-time|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 열 삭제\n",
        "foo3 = foo2.drop(\"delay\")\n",
        "foo3.show()"
      ],
      "metadata": {
        "id": "L_UXCLdcWPeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba71a93-d52d-44ee-e1a8-dca290bf7144"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+-----------+-------+\n",
            "|    date|distance|origin|destination| status|\n",
            "+--------+--------+------+-----------+-------+\n",
            "|01010710|     590|   SEA|        SFO|Delayed|\n",
            "|01010955|     590|   SEA|        SFO|Delayed|\n",
            "|01010730|     590|   SEA|        SFO|On-time|\n",
            "+--------+--------+------+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼명 바꾸기\n",
        "foo4 = foo3.withColumnRenamed(\"status\", \"flight_status\")\n",
        "foo4.show()"
      ],
      "metadata": {
        "id": "SJgOWWk4WXVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657d432c-0528-435e-e857-4ca14bbf8a30"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+-----------+-------------+\n",
            "|    date|distance|origin|destination|flight_status|\n",
            "+--------+--------+------+-----------+-------------+\n",
            "|01010710|     590|   SEA|        SFO|      Delayed|\n",
            "|01010955|     590|   SEA|        SFO|      Delayed|\n",
            "|01010730|     590|   SEA|        SFO|      On-time|\n",
            "+--------+--------+------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SEA에서 출발하는 항공편 도착지, 월, 지연 컬럼으로 query\n",
        "SELECT destination, CAST(SUBSTRING(date, 0, 2)AS int) AS month, delay\n",
        "FROM departureDelays\n",
        "WHERE origin = \"SEA\""
      ],
      "metadata": {
        "id": "BNym4g4XWime"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 쿼리를 목적지 및 월별 지연(평균과 최대)에 대한 집계 계산하기\n",
        "SELECT destination, CAST(SUBSTRING(date, 0, 2)AS int) AS month, delay\n",
        "FROM departureDelays\n",
        "WHERE origin = \"SEA\"\n",
        ")\n",
        "PIVOT (\n",
        "    CAST(AVG(delay) AS DECIMAL(4, 2)) AS AvgDelay, MAX(delay) AS MaxDelay FOR month IN (1 JAN, 2 FEB)\n",
        ")\n",
        "ORDER BY destination"
      ],
      "metadata": {
        "id": "YXhMCsaDXFrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}